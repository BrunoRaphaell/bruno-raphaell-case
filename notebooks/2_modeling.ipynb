{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "916b3656-4d81-44b1-9eb0-ff9faa05acf4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "instalando a ultima versão do mlflow"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade -Uqqq mlflow>=3.0 xgboost optuna uv\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "062ab1d0-d7b2-4501-8322-4d4eb636f1f4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "importando as bibliotecas necessárias"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import optuna\n",
    "from functools import partial\n",
    "from mlflow import MlflowClient\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96c1ae88-90bb-43f9-893f-01c3b91d5397",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Constantes"
    }
   },
   "outputs": [],
   "source": [
    "PATH_BASE_PROCESSADA = 'workspace.processed.base_processada'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d735c2b3-e385-47c5-86f6-a07b3e6f6368",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ajustando nível de log"
    }
   },
   "outputs": [],
   "source": [
    "# Vamos usar para não poluir demais as saídas do MLFlow\n",
    "\n",
    "mlflow_logger = logging.getLogger(\"mlflow\")\n",
    "mlflow_logger.setLevel(logging.ERROR)\n",
    "print(\"Nível de log do MLflow ajustado para ERROR. Apenas erros serão exibidos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "949ef157-0da5-40eb-9bed-ddd5bd61c02c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "lendo a base de dados"
    }
   },
   "outputs": [],
   "source": [
    "dados = spark.table(PATH_BASE_PROCESSADA).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18348a5b-5018-415e-a2f2-ad8b943d30c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Configurando o Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63e10efc-2f78-41c5-bf70-60a4028a048e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código abaixo serve para configurar o local onde o MLflow vai registrar e gerenciar os modelos. O parâmetro \"databricks-uc\" é um alias que indica que o Registry de Modelos do MLflow deve ser integrado ao Unity Catalog do Databricks. Caso não fosse inserido essa linha os modelos ficam no registry local do MLflow ao inserir, os modelos ficam registrados no Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bf08661-4d0b-4d42-a1fa-4c2f4ae44a9a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Registry de Modelos do MLflow"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb1a5540-2c22-40d1-abb0-18ba4064a8dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff069d71-0511-43e1-a826-5711546bcdfa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Definindo a paleta de cores do ifood"
    }
   },
   "outputs": [],
   "source": [
    "minhas_cores = [\n",
    "    '#FE3054', # vermelho vibrante\n",
    "    '#F94EB6', # rosa choque\n",
    "    '#FFB020', # amarelo ouro\n",
    "    '#FA781A', # laranja intenso\n",
    "    '#FEF6C8', # bege claro\n",
    "    '#06516E', # azul petróleo\n",
    "    '#06987B', # verde esmeralda\n",
    "    '#260607'  # vinho quase preto\n",
    "]\n",
    "\n",
    "minha_paleta = sns.color_palette(minhas_cores)\n",
    "\n",
    "sns.palplot(minha_paleta)\n",
    "plt.title(\"Minha Paleta Personalizada\")\n",
    "plt.show()\n",
    "\n",
    "sns.set_palette(minha_paleta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e72c2ebb-73f4-46fa-a0cb-ff6ee77acefc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Funções para visualização"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc_auc(y_test, y_scores):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(fpr, tpr, color='#FE3054', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "    ax.plot([0, 1], [0, 1], color='gray', linestyle='--') \n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Curva ROC')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid()\n",
    "    \n",
    "    return fig \n",
    "\n",
    "\n",
    "def plot_matriz_confusao(y_true_teste, y_pred_teste, group_names=None,\n",
    "                         categories='auto', count=True,\n",
    "                         xyticks=True, sum_stats=True, figsize=None,\n",
    "                         title=None):\n",
    "\n",
    "    cf = confusion_matrix(y_true_teste, y_pred_teste)\n",
    "\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names) == cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}\".strip()\n",
    "                  for v1, v2 in zip(group_labels, group_counts)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
    "\n",
    "    if sum_stats:\n",
    "        accuracy = accuracy_score(y_true_teste, y_pred_teste)\n",
    "        precision = precision_score(y_true_teste, y_pred_teste)\n",
    "        recall = recall_score(y_true_teste, y_pred_teste)\n",
    "        f1_score_metric = f1_score(y_true_teste, y_pred_teste)\n",
    "\n",
    "        stats_text = \"Acurácia = {:0.3f}\\nPrecisão = {:0.3f}\\nRecall = {:0.3f}\\nF1 Score = {:0.3f}\".format(\n",
    "            accuracy, precision, recall, f1_score_metric)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks is False:\n",
    "        categories = False\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cf, annot=box_labels, fmt=\"\", cbar=False,\n",
    "                xticklabels=categories, yticklabels=categories, ax=ax)\n",
    "    \n",
    "\n",
    "    ax.text(cf.shape[1] + 0.7, cf.shape[0] / 2.0, stats_text, ha='left', va='center', fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('Valores verdadeiros', fontsize=17)\n",
    "    ax.set_xlabel('Valores preditos', fontsize=17)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=20, pad=20)\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0, 0.85, 1]) \n",
    "    return fig\n",
    "\n",
    "\n",
    "def heatmap_corr(df: pd.DataFrame, figsize: tuple = (8, 6)):\n",
    "    \"\"\"\n",
    "    Gera um heatmap de correlação triangular para um DataFrame.\n",
    "\n",
    "    Argumentos:\n",
    "        df (pd.DataFrame): O DataFrame de entrada com dados numéricos.\n",
    "        figsize (tuple, optional): O tamanho da figura (largura, altura). Padrão é (8, 6).\n",
    "    \"\"\"\n",
    "\n",
    "    corr = df.corr(numeric_only=True)\n",
    "    \n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    ax = sns.heatmap(corr,\n",
    "                mask=mask,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                xticklabels=corr.columns.values,\n",
    "                yticklabels=corr.columns.values)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), ha='right')\n",
    "    \n",
    "    plt.title('Heatmap de Correlação')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plotar_outliers(X: pd.DataFrame, n_cols: int = 3) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Cria uma grade de boxplots para detectar outliers em cada variável.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): DataFrame contendo as variáveis.\n",
    "        n_cols (int): Número de colunas no layout da grade.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: Objeto Figure do matplotlib contendo os gráficos de outliers.\n",
    "    \"\"\"\n",
    "    features = X.columns\n",
    "    n_features = len(features)\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten() if n_rows * n_cols > 1 else [axes]\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        if i < len(axes):\n",
    "            ax = axes[i]\n",
    "            sns.boxplot(x=X[feature], ax=ax)\n",
    "            ax.set_title(f'{feature}')\n",
    "            ax.set_xlabel(feature)\n",
    "\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Detecção de outliers para as variáveis', y=1.02, fontsize=16)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_countplot(\n",
    "    dados: pd.DataFrame,\n",
    "    coluna: str,\n",
    "    titulo: str = \"\",\n",
    "    figsize: tuple = (8, 5),\n",
    "    palette: list = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plota um countplot (gráfico de contagem) usando Seaborn.\n",
    "\n",
    "    Args:\n",
    "        dados (pd.DataFrame): DataFrame com os dados.\n",
    "        coluna (str): Nome da coluna categórica a ser plotada.\n",
    "        titulo (str, opcional): Título do gráfico.\n",
    "        figsize (tuple, opcional): Tamanho da figura (largura, altura). Padrão (8,5).\n",
    "        palette (list, opcional): Lista de cores personalizadas\n",
    "\n",
    "    Returns:\n",
    "        Figura com o gráfico.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    ax = sns.countplot(\n",
    "        data=dados,\n",
    "        x=coluna,\n",
    "        palette=palette\n",
    "    )\n",
    "\n",
    "    # Exibir valores acima das barras\n",
    "\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fontsize=12)\n",
    "\n",
    "    # Título e formatação\n",
    "    plt.title(titulo, fontsize=16, fontweight=\"bold\", loc=\"left\")\n",
    "    plt.xlabel(coluna, fontsize=13)\n",
    "    plt.ylabel(\"Contagem\", fontsize=13)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4526e3c6-8062-4f92-939a-a6d374e1161c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dados.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca624ff-4700-4044-8106-e7b4bb2c2237",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "selecionando as colunas"
    }
   },
   "outputs": [],
   "source": [
    "colunas_selecionadas = ['receive_time', 'valor_gasto_na_jornada', 'qtd_transacoes_na_jornada', 'ticket_medio_na_jornada', 'age', 'credit_card_limit', 'discount_value', 'duration', 'min_value', 'tempo_de_registro', 'num_channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bebaa6f4-1a0e-409e-9e0d-f8bf70a93b23",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Detecção de outliers"
    }
   },
   "outputs": [],
   "source": [
    "plotar_outliers(dados[colunas_selecionadas])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec330751-662d-4704-accd-9fd7ccdd2c25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Essas variáveis que apresentam outliers (`valor_gasto_na_jornada`, `qtd_transacoes_na_jornada` e `ticket_medio_na_jornada`) pela detecção usando o IQR, serão removidas posteriormente, na etapa de modelagem. \n",
    "\n",
    "Mas aqui servem para gente entender um pouco como é o perfil de consumo. Podemos tirar 3 principais conclusões:\n",
    "\n",
    " * Todas as 3 variáveis possuem forte assimetria à direita, ou seja, a maioria dos clientes tem valores baixos deixando a grande massa dos dados concentrada perto de 0. \n",
    " \n",
    " * Poucos cliêntes têm valores muitos altos\n",
    "\n",
    " * Essa assimatria faz com que a média seja maior que a mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21336fba-11ce-4b21-914d-9ae98165fcfe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Gráfico de correlação"
    }
   },
   "outputs": [],
   "source": [
    "heatmap_corr(dados[colunas_selecionadas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "812df08f-44d2-4c58-b45c-8f3ba0776e69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Nesse gráfico de correlação, há 3 relações que chamam a atenção:\n",
    "\n",
    "  * `ticket_medio_na_jornada` e `valor_gasto_na_jornada` → 0.79\n",
    "    → Faz sentido: quanto maior o gasto total, maior tende a ser o ticket médio.\n",
    "  * `min_value` e `duration` → 0.47\n",
    "    → Ofertas de maior valor mínimo tendem a ter maior duração.\n",
    "  * `min_value` e `credit_card_limit` → 0.31\n",
    "    → Usuários com maior limite de cartão tendem a receber/completar ofertas com valor mínimo mais alto.\n",
    "  * `qtd_transacoes_na_jornada` e `valor_gasto_na_jornada` → 0.40\n",
    "    → Mais transações aumentam o gasto total, de forma esperada.\n",
    "  * `tempo_de_registro` tem correlação **negativa** com `min_value` (-0.32).\n",
    "    → Clientes mais antigos tendem a lidar com ofertas de valor mínimo menor.\n",
    "\n",
    "A correlação forte entre `valor_gasto_na_jornada` e `ticket_medio_na_jornada` sugere que talvez não seja necessário manter ambas no modelo de machine learning porque carregam informação semelhante. Mas como mencionado anteriormente, essas duas colunas vão ser removidas, portando não devemos nos preocupar com elas.\n",
    "\n",
    "As demais correlações não são significativas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a531af1-9f29-4e7d-8468-8f59ddfe3010",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "distribuição da variável alvo"
    }
   },
   "outputs": [],
   "source": [
    "plot_countplot(dados, 'target', 'Distribuição target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff5cbf9e-9370-4c7a-ae27-8d2e0e8b1872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Portando a base de dados está com um bom balanceamento. Não sendo necessário aplicar técnicas para tratar isso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76d3bff2-f1b4-46b6-89df-355c57fa40ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Desenvolvimento dos modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2e6fc8a-478a-4241-a8cd-cfdb83726530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Devemos primeiro definir qual métrica vamos maximizar, considerando a necessidade do negócio. Nosso objetivo é desenvolver um modelo que auxilie na decisão de qual oferta enviar para cada cliente. Entre as opções temos:\n",
    "\n",
    "* Acurácia: Mede a proporção de previsões corretas, ou seja, tanto de clientes que aceitariam a oferta e dos que não aceitariam, em relação ao total de previsões. \n",
    "\n",
    "$$\n",
    "\\text{Acurácia} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "* Precisão (precision): Mede, de todas as vezes em que o modelo previu que um cliente aceitaria a oferta, quantas vezes de fato ele acertou. Uma alta precisão é importante em casos onde o custo do FALSO POSITIVO  é alto. Para o nosso contexto, um FALSO POSITIVO é um cliente que o modelo que disse aceitaria a oferta, mas na realidade não aceita. O custo real seria enviar uma oferta para um cliente que não vai converter. \n",
    "\n",
    "$$\n",
    "\\text{Precisão} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "* Recall (sensibilidade): Mede, de todos os clientes que realmente aceitariam a oferta, quantos o modelo conseguiu identificar corretamente. Um alto recall é importante quando o custo de um FALSO NEGATIVO é alto. Um FALSO NEGATIVO para o nosso contexto seria um cliente que aceitaria a oferta, mas o modelo previu que não, e portanto a oferta não é enviada para ele. O custo seria a perda.\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "* F1-Score: É a média harmônica entre Precisão e Recall. É útil quando é necessário ter um equilíbrio entre as duas. F1-Score somente é alto quando ambas as métricas forem altas também.  \n",
    "\n",
    "$$\n",
    "\\text{F1-Score} = \\frac{2 \\cdot \\text{Precisão} \\cdot \\text{Recall}}{\\text{Precisão} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "* AUC-ROC: A curva ROC mostra a capacidade do modelo de distinguir entre as classes positivas e negativa. A AUC é area sob essa curva que varia entre 0.5 e 1. Avalia o desempenho do modelo em todos os limiares possíveis. \n",
    "\n",
    "Pensando no problema, o F1-Score é a métrica que eu escolhi para maximizar que está alinhada com os objetivos do negócio. O F1 vai me dar um ótimo balanço entre não despedicar as ofertas (Precisão) e não perder oportunidades (Recall). Vamos mostrar todas as métricas, mas nosso foco em maximizar vai ser o **F1-SCORE**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5cd7b9f-1d07-444a-85b8-caa9e0f85e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Estrutura do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f991d08b-755e-4094-bb68-e5fcd1a4e297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Registrar o modelo usando MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b4cc9d-3b49-4c91-9509-f8989954d7b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Quando registramos um modelo no Databricks com a ajuda do MLFlow, artefatos e metadatos importante são capturados. Isso garante que o modelo desenvolvido, não seja apenas capaz de ser reproduzido no ambiente, mas também que esteja completamente pronto para a implantação com as dependências necessárias.\n",
    "\n",
    "![](https://www.databricks.com/wp-content/uploads/2020/04/databricks-adds-access-control-to-mlflow-model-registry_01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc07f2b-4b12-4ad6-8fe2-42b99c321b5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Formulação do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8704f125-79c5-41f1-9265-27ed41318d89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "A formulação do projeto que vamos adotar é estimar a probabilidade de conversão para cada cliente por oferta e então escolher a oferta com maior probabilidade. Isso é mais útil que treinar um modelo que vai apenas dizer \"O cliente vai aceitar a oferta\".\n",
    "\n",
    "\n",
    "A minha proposta é aplicar 2 técnicas de modelagem de *machine learning*, sendo elas:\n",
    "\n",
    "* *Bagging*;\n",
    "* *Boosting*.\n",
    "\n",
    "Após a aplicação dessas técnicas, analisaremos qual apresentou o melhor desempenho de acordo com a métrica escolhida. \n",
    "\n",
    "Antes de passarmos para as técnicas, precisamos definir um modelo como *baseline* a ser ultrapassado. Vamos utilizar o `DecisionTreeClassifier` como nosso *baseline* já que todos os modelos que vamos utilizar serão baseados em árvores e `DecisionTreeClassifier` seria o mais simples de todos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7658b610-0ff7-4141-8872-8e985a460826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Bagging - RandomForestClassifier\n",
    "\n",
    "Bagging vem de *Bootstrap Aggregating*:\n",
    "\n",
    "* Bootstrap = criar várias amostras diferentes dos dados originais (com reposição).\n",
    "\n",
    "* Aggregating = juntar as previsões de todos os modelos (por média ou votação)\n",
    "\n",
    "\n",
    "**Funcionamento:**\n",
    "\n",
    "1. Temos o conjunto de dados inicial.\n",
    "\n",
    "2. Gera diversas amostras aleatórias com reposição a partir desse conjunto de dados.\n",
    "\n",
    "3. Para cada amostra aleatória gerada, treina um modelo diferente (uma árvore de decisão no nosso caso).\n",
    "\n",
    "4. Ao final, junta os resultados de todos os modelos. Como é uma classificação, o resultado será a votação da maioria. \n",
    "\n",
    "![](https://i.imgur.com/EGDJjvk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc3189a-80f1-401b-8a7f-08d00685f1e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Boosting - XGBoost\n",
    "\n",
    "Boosting é uma técnica que vai aprendendo com erros dos preditores anteriores, ou seja, modelos simples que são treinados em sequência, onde cada um tenta corrigir os erros dos anteriores. \n",
    "\n",
    "**Funcionamento:**\n",
    "\n",
    "1. Temos a base de dados inicial\n",
    "2. Treinamos o primeiro modelo\n",
    "3. Avaliamos onde ele errou\n",
    "4. Dá mais peso para os exemplos onde ele errou\n",
    "5. Treina o segundo modelo, porém focando em corrigir esses erros\n",
    "6. Repete o processo, até o total de modelos indicados (no nosso caso o número de árvores de decisão)\n",
    "7. Combina todas as previsões (Geralmente usando uma média ponderada ou soma com pesos)\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/N4IRnZP.png)\n",
    "\n",
    "Para a nosa implementação usaremos o [XGBoost](https://xgboost.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "992d77b8-ec7c-4588-a5c8-a7921e1834b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Implementando a estrutura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a00c584-ed62-4232-b72a-f0e45333a2e7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Separando em X e y"
    }
   },
   "outputs": [],
   "source": [
    "X = dados.drop(columns=['target'])\n",
    "y = dados['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "412e7cd5-e7b7-4c57-948b-0199f57f5a13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da2f835c-1071-4464-b0a8-11164af0a0c7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Selecionando colunas"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = ['receive_time', 'age', 'credit_card_limit',\n",
    "        'tempo_de_registro', 'discount_value', 'duration',\n",
    "       'min_value', 'num_channels', 'email',\n",
    "       'mobile', 'social', 'web']\n",
    "\n",
    "cat_cols = ['gender', 'offer_type', 'categoria_duracao']\n",
    "\n",
    "cols_drop = ['account_id', 'offer_id_final', 'offer_received', 'offer_viewed',\n",
    "    'valor_gasto_na_jornada', 'qtd_transacoes_na_jornada',\n",
    "    'ticket_medio_na_jornada', 'registered_on', 'channels']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be770c5c-690b-4212-a67f-64a74c55cf30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Removemos `account_id` e `offer_id_final` pois são identificadores. `registered_on` é uma data, e já temos o `tempo_de_registro` como uma variável numérica.\n",
    "\n",
    "O motivo de remover `valor_gasto_na_jornada`, `qtd_transacoes_na_jornada` e `ticket_medio_na_jornada` é um pouco mais interessante. Essas variáveis contém informações sobre o resultado que estamos tentando prever, mas que só estariam disponíveis depois do evento acontecer. Nosso objetivo é prever se um cliente vai completar a oferta antes de enviá-la. O valor que o cliente gastou após visualizar a oferta ou mesmo depois de receber poderia dar dicas ao modelo que não queremos. Seria algo como \"Se o cliente gastou muito após visualizar a oferta, preveja que ele vai completar\". Mas no momento do envio da oferta não sabemos se ele vai gastar muito ou pouco. \n",
    "\n",
    "`offer_received` e `offer_viewed` são as variáveis da \"história\" do cliente, como mencionado no notebook 1. Essas variáveis indicam os estágios da conversão. `offer_received` sempre vai ser 1 para todas as linhas. Elas também não ajudam na decisão principal. A decisão de \"qual oferta enviar\" acontece antes mesmo de sabermos se o cliente irá sequer visualizá-la. Incluir a coluna `offer_viewed` pode confundir o modelo. Queremos prever o sucesso da oferta do cliente, e as características do cliente e da oferta são as causas que levam a esse sucesso.`channels` é uma variável que já foi transformada no notebook 01. Foi mantida apenas para ser utilizada no Dashboard Power Bi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d253419d-72ec-4dc0-97b6-cf90419fb826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Pipeline de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48e2ef66-be27-4974-b716-5afc1ad50eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O pipeline de ML abaixo está englobando algumas etapas do processo de modelagem, como:\n",
    "\n",
    "* Treinamento do modelo de machine learning. Nesse caso estamos testando 3 modelos. Decision Tree, Random Forest e XGBoost.\n",
    "\n",
    "* Otimização dos hiperparâmetros desses modelos para decidir qual técnica/modelo teve melhor desempenho. Para avaliar com mais precisão utilizamos a validação cruzada. \n",
    "\n",
    "* Registro no MLFlow dos 3 melhores modelos otimizados.\n",
    "\n",
    "* Salvar os 3 melhores modelos no Unity Catalog utilizando o MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0724b6d7-49c9-4df0-985f-52d80e04650c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Definindo os espaços de busca dos modelos"
    }
   },
   "outputs": [],
   "source": [
    "def espaco_busca_dt(trial):\n",
    "    # Espaço de busca para árvore de decisão\n",
    "\n",
    "    return {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'random_state': 42\n",
    "\n",
    "        # Demais hiperâmetros que serão otimidos por questão de velocidade do código. \n",
    "\n",
    "    }\n",
    "\n",
    "def espaco_busca_rf(trial):\n",
    "    # Espaço de busca para o random forest\n",
    "\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'random_state': 42\n",
    "\n",
    "        # Demais hiperâmetros que serão otimidos por questão de velocidade do código. \n",
    "    }\n",
    "\n",
    "def espaco_busca_xgb(trial):\n",
    "    # Espaço de busca para o XGBoost\n",
    "\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 400, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'random_state': 42\n",
    "\n",
    "        # Demais hiperâmetros que serão otimidos por questão de velocidade do código. \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99aec300-fdf7-4afc-b298-4715e8840d6b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Definindo a função objetivo"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, classe_modelo, espaco_busca, X_train, y_train, X_test, y_test, cat_cols, num_cols):\n",
    "\n",
    "    # Diz ao Optuna como avaliar se uma combinação de parâmetros é boa ou ruim.\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        \n",
    "        params = espaco_busca(trial)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        model = classe_modelo(**params)\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', num_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        \n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        # Validação cruzada\n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=skf, scoring='f1')\n",
    "\n",
    "        # Valor a ser maximizado na otimização de hiperparâmetros\n",
    "        mean_f1 = np.mean(scores)\n",
    "\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ffee202-611b-4e61-9b94-de16fd1f1894",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Pipeline de ML"
    }
   },
   "outputs": [],
   "source": [
    "def otimizar_e_registrar_modelo(\n",
    "    X, y, colunas_para_dropar, cat_cols, num_cols, \n",
    "    nome_modelo, classe_modelo, espaco_busca_modelo, \n",
    "    n_trials=10\n",
    "):\n",
    "\n",
    "    X_model = X.drop(columns=colunas_para_dropar)\n",
    "    X_model[num_cols] = X_model[num_cols].astype(\"float64\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_model, y, random_state=42, stratify=y)\n",
    "    \n",
    "    TZ_MINUS3 = timezone(timedelta(hours=-3))\n",
    "    timestamp = datetime.now(TZ_MINUS3).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_name = f\"Otimizacao_{nome_modelo}_{timestamp}\"\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as parent_run:\n",
    "        print(f\"--- Iniciando otimização para o modelo: {nome_modelo} ---\")\n",
    "        mlflow.set_tag(\"model_type\", nome_modelo)\n",
    "\n",
    "        objective_com_dados = partial(\n",
    "            objective,\n",
    "            classe_modelo=classe_modelo,\n",
    "            espaco_busca=espaco_busca_modelo,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test, y_test=y_test,\n",
    "            cat_cols=cat_cols, num_cols=num_cols\n",
    "        )\n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective_com_dados, n_trials=n_trials)\n",
    "        \n",
    "        mlflow.log_params(study.best_params)\n",
    "\n",
    "        best_model = classe_modelo(**study.best_params)\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', num_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "            ]\n",
    "        )\n",
    "        best_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', best_model)])\n",
    "        best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = best_pipeline.predict(X_test)\n",
    "        y_pred_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "        metrics = {\n",
    "            'Acurácia': accuracy_score(y_test, y_pred),\n",
    "            'Precisão': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred)\n",
    "        }\n",
    "\n",
    "        print(\"Gerando e registrando visualizações...\")\n",
    "        \n",
    "        labels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "        categories = [\"Não completada\", \"Completada\"]\n",
    "        \n",
    "        fig_cm = plot_matriz_confusao(\n",
    "            y_test, \n",
    "            y_pred, \n",
    "            group_names=labels,\n",
    "            categories=categories,\n",
    "            title=f\"Matriz de Confusão para {best_model.__class__.__name__}\",\n",
    "            figsize=(15, 5)\n",
    "        )\n",
    "        mlflow.log_figure(fig_cm, \"matriz_de_confusao.png\")\n",
    "        plt.close(fig_cm)\n",
    "        \n",
    "        fig_roc = plot_roc_auc(y_test, y_pred_proba)\n",
    "        mlflow.log_figure(fig_roc, \"curva_roc_auc.png\")\n",
    "        plt.close(fig_roc)\n",
    "\n",
    "        print(f\"Registrando o modelo '{nome_modelo}' no MLflow...\")\n",
    "\n",
    "        # Modelo e Avaliação Automática\n",
    "        signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "        local_salvo = f\"workspace.modelos_ml.{nome_modelo}\"\n",
    "\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=best_pipeline,\n",
    "            artifact_path=\"modelo\",\n",
    "            signature=signature,\n",
    "            registered_model_name=local_salvo\n",
    "        )\n",
    "\n",
    "        evaluation_data = X_test.copy()\n",
    "        evaluation_data[\"target\"] = y_test\n",
    "        mlflow.models.evaluate(\n",
    "            model=model_info.model_uri,\n",
    "            data=evaluation_data,\n",
    "            targets=\"target\",\n",
    "            model_type=\"classifier\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Modelo '{nome_modelo}' otimizado e registrado com sucesso!\")\n",
    "        return local_salvo, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aa57bd7-5172-402e-bf33-afd95008f7fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Testando e registrando os modelos"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_CONFIG = {\n",
    "    \"ArvoreDecisao\": {\n",
    "        \"classe_modelo\": DecisionTreeClassifier,\n",
    "        \"espaco_busca_modelo\": espaco_busca_dt\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"classe_modelo\": RandomForestClassifier,\n",
    "        \"espaco_busca_modelo\": espaco_busca_rf\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"classe_modelo\": XGBClassifier,\n",
    "        \"espaco_busca_modelo\": espaco_busca_xgb\n",
    "    }\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for model_name, config in MODEL_CONFIG.items():\n",
    "    \n",
    "    # Otimiza o modelo atual\n",
    "    local_salvo, info_modelo = otimizar_e_registrar_modelo(\n",
    "        X=X, \n",
    "        y=y,\n",
    "        colunas_para_dropar=cols_drop,\n",
    "        cat_cols=cat_cols,\n",
    "        num_cols=num_cols,\n",
    "        nome_modelo=f\"ModeloOferta_{model_name}\",\n",
    "        classe_modelo=config['classe_modelo'],\n",
    "        espaco_busca_modelo=config['espaco_busca_modelo'],\n",
    "        n_trials=10 \n",
    "    )\n",
    "    \n",
    "    info_modelo['caminho'] = local_salvo\n",
    "    resultados.append(info_modelo)\n",
    "\n",
    "results_df = pd.DataFrame(resultados).sort_values(by='f1_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb9cceb0-4b8f-4d05-90ff-cfaebe5a3d8b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Comparativo modelos"
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Comparativo Final dos Modelos Otimizados ---\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97b3a499-94c4-4b92-9fc1-67a63b054148",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Olhando para o *f1_score* os 3 tiveram praticamente um empate técnico. Porém, os Falsos Negativos do modelo Random Forest foram menores e, pensando no negócio, considero que os Falsos Negativos que representam um cliente que aceitaria a oferta, mas o modelo previu que não, são mais prejudiciais do que os Falsos Positivos. Portanto visando maximizar ganhos, vamos escolher o modelo Random Forest. Poderíamos ter tido as mesmas conclusões olhando para o **recall** como métrica secundária. Para garantir que quem tá executando o código consiga ver a imagem abaixo, vai ser disponilizado em markdown as imagens da matrizes de confusão, mas na entrevista pretendo mostrar no mlflow a comparação. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dcfb5a8-4d15-4856-8bd0-35ff328f7505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Matriz de confusão para decision tree**\n",
    "![](https://i.imgur.com/QvNGiJc.png)\n",
    "\n",
    "**Matriz de confusão random forest**\n",
    "![](https://i.imgur.com/H5fqqIW.png)\n",
    "\n",
    "**Matriz de confusão XGBoost**\n",
    "![](https://i.imgur.com/0z7gO3X.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c47a8fc7-cefc-4651-803c-ddbb8b027617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prevendo qual oferta enviar para determinado cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c03c130-a96f-40ea-9f30-3e756e3456f8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Atribuindo um alias para o modelo escolhido"
    }
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "versao_modelo = 1\n",
    "client.set_registered_model_alias(\"workspace.modelos_ml.ModeloOferta_RandomForest\", \"producao\", versao_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "500f9656-326c-47ef-864c-cac54712802c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dados.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4da0e9e-8604-4e62-8a8c-17aba89479fe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Prevendo as probabilidades de cada oferta"
    }
   },
   "outputs": [],
   "source": [
    "model_uri = \"models:/workspace.modelos_ml.ModeloOferta_RandomForest@producao\"\n",
    "\n",
    "print(f\"Carregando modelo: {model_uri}\")\n",
    "load_model = mlflow.sklearn.load_model(model_uri)\n",
    "print(\"Modelo carregado!\")\n",
    "\n",
    "base = X.drop(columns=cols_drop, errors=\"ignore\")\n",
    "df_cliente = (\n",
    "    base.loc[:, ['age', 'credit_card_limit', 'gender', 'tempo_de_registro', 'receive_time']]\n",
    "        .sample(1)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "offer_features = [\n",
    "    'offer_id_final', 'discount_value', 'duration', 'min_value', 'offer_type',\n",
    "    'categoria_duracao', 'num_channels', 'email', 'mobile', 'social', 'web'\n",
    "]\n",
    "offer_features = list(dict.fromkeys(offer_features))  # garante unicidade mantendo ordem\n",
    "dados_ofertas = dados.loc[:, offer_features].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_scoring = df_cliente.merge(dados_ofertas, how='cross')\n",
    "\n",
    "colunas_modelo = base.columns.tolist()\n",
    "df_scoring = df_scoring.reindex(columns=colunas_modelo, fill_value=0)\n",
    "\n",
    "print(\"Dados do cliente: \")\n",
    "display(df_cliente)\n",
    "\n",
    "print(\"Calculando a probabilidade de aceite para cada oferta...\")\n",
    "probabilidade_aceite = load_model.predict_proba(df_scoring)[:, 1] * 100\n",
    "\n",
    "df_proba_sorted = (\n",
    "    dados_ofertas.assign(probabilidade_aceite=probabilidade_aceite.round(2))\n",
    "                 .sort_values('probabilidade_aceite', ascending=False)\n",
    "                 .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(df_proba_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "943b470a-e3dc-47df-80df-f06908840061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extra (Mostrar servindo o modelo)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_modeling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

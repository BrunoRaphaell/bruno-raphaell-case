{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "916b3656-4d81-44b1-9eb0-ff9faa05acf4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "instalando a ultima versão do mlflow"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade -Uqqq mlflow>=3.0 xgboost optuna uv\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "062ab1d0-d7b2-4501-8322-4d4eb636f1f4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "importando as bibliotecas necessárias"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d735c2b3-e385-47c5-86f6-a07b3e6f6368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "mlflow_logger = logging.getLogger(\"mlflow\")\n",
    "mlflow_logger.setLevel(logging.ERROR)\n",
    "print(\"Nível de log do MLflow ajustado para ERROR. Apenas erros serão exibidos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "949ef157-0da5-40eb-9bed-ddd5bd61c02c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "lendo a base de dados"
    }
   },
   "outputs": [],
   "source": [
    "dados = spark.table('workspace.processed.base_processada').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc36aef0-9b2f-4320-8a3a-2b16255a8214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "colunas_dropar = ['account_id', 'offer_id_final', 'registered_on']\n",
    "dados_drop = dados.drop(columns=colunas_dropar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "116d33d0-9c7c-47aa-a33e-6f80dca53bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = dados_drop.drop(columns=['target'])\n",
    "y = dados_drop['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18348a5b-5018-415e-a2f2-ad8b943d30c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Configurando o Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63e10efc-2f78-41c5-bf70-60a4028a048e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O código abaixo serve para configurar o local onde o MLflow vai registrar e gerenciar os modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bf08661-4d0b-4d42-a1fa-4c2f4ae44a9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb1a5540-2c22-40d1-abb0-18ba4064a8dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff069d71-0511-43e1-a826-5711546bcdfa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Definindo a paleta de cores do ifood"
    }
   },
   "outputs": [],
   "source": [
    "minhas_cores = [\n",
    "    '#FE3054', # vermelho vibrante\n",
    "    '#F94EB6', # rosa choque\n",
    "    '#FFB020', # amarelo ouro\n",
    "    '#FA781A', # laranja intenso\n",
    "    '#FEF6C8', # bege claro\n",
    "    '#06516E', # azul petróleo\n",
    "    '#06987B', # verde esmeralda\n",
    "    '#260607'  # vinho quase preto\n",
    "]\n",
    "\n",
    "minha_paleta = sns.color_palette(minhas_cores)\n",
    "\n",
    "sns.palplot(minha_paleta)\n",
    "plt.title(\"Minha Paleta Personalizada\")\n",
    "plt.show()\n",
    "\n",
    "sns.set_palette(minha_paleta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e72c2ebb-73f4-46fa-a0cb-ff6ee77acefc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Funções para visualização"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_roc_auc(y_test, y_scores):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(fpr, tpr, color='#FE3054', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "    ax.plot([0, 1], [0, 1], color='gray', linestyle='--') \n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Curva ROC')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid()\n",
    "    \n",
    "    return fig \n",
    "\n",
    "\n",
    "def plot_matriz_confusao(y_true_teste, y_pred_teste, group_names=None,\n",
    "                         categories='auto', count=True,\n",
    "                         xyticks=True, sum_stats=True, figsize=None,\n",
    "                         title=None):\n",
    "\n",
    "    cf = confusion_matrix(y_true_teste, y_pred_teste)\n",
    "\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names) == cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}\".strip()\n",
    "                  for v1, v2 in zip(group_labels, group_counts)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
    "\n",
    "    if sum_stats:\n",
    "        accuracy = accuracy_score(y_true_teste, y_pred_teste)\n",
    "        precision = precision_score(y_true_teste, y_pred_teste)\n",
    "        recall = recall_score(y_true_teste, y_pred_teste)\n",
    "        f1_score_metric = f1_score(y_true_teste, y_pred_teste)\n",
    "\n",
    "        stats_text = \"Acurácia = {:0.3f}\\nPrecisão = {:0.3f}\\nRecall = {:0.3f}\\nF1 Score = {:0.3f}\".format(\n",
    "            accuracy, precision, recall, f1_score_metric)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "    if figsize is None:\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks is False:\n",
    "        categories = False\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(cf, annot=box_labels, fmt=\"\", cbar=False,\n",
    "                xticklabels=categories, yticklabels=categories, ax=ax)\n",
    "    \n",
    "\n",
    "    ax.text(cf.shape[1] + 0.7, cf.shape[0] / 2.0, stats_text, ha='left', va='center', fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('Valores verdadeiros', fontsize=17)\n",
    "    ax.set_xlabel('Valores preditos', fontsize=17)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=20, pad=20)\n",
    "    \n",
    "    fig.tight_layout(rect=[0, 0, 0.85, 1]) \n",
    "    return fig\n",
    "\n",
    "\n",
    "def heatmap_corr(df: pd.DataFrame, figsize: tuple = (8, 6)):\n",
    "    \"\"\"\n",
    "    Gera um heatmap de correlação triangular para um DataFrame.\n",
    "\n",
    "    Argumentos:\n",
    "        df (pd.DataFrame): O DataFrame de entrada com dados numéricos.\n",
    "        figsize (tuple, optional): O tamanho da figura (largura, altura). Padrão é (8, 6).\n",
    "    \"\"\"\n",
    "\n",
    "    corr = df.corr(numeric_only=True)\n",
    "    \n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    ax = sns.heatmap(corr,\n",
    "                mask=mask,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                xticklabels=corr.columns.values,\n",
    "                yticklabels=corr.columns.values)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), ha='right')\n",
    "    \n",
    "    plt.title('Heatmap de Correlação')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plotar_outliers(X: pd.DataFrame, n_cols: int = 3) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Cria uma grade de boxplots para detectar outliers em cada variável.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): DataFrame contendo as variáveis.\n",
    "        n_cols (int): Número de colunas no layout da grade.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: Objeto Figure do matplotlib contendo os gráficos de outliers.\n",
    "    \"\"\"\n",
    "    features = X.columns\n",
    "    n_features = len(features)\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes = axes.flatten() if n_rows * n_cols > 1 else [axes]\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        if i < len(axes):\n",
    "            ax = axes[i]\n",
    "            sns.boxplot(x=X[feature], ax=ax)\n",
    "            ax.set_title(f'{feature}')\n",
    "            ax.set_xlabel(feature)\n",
    "\n",
    "    for i in range(n_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Detecção de outliers para as variáveis', y=1.02, fontsize=16)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_countplot(\n",
    "    dados: pd.DataFrame,\n",
    "    coluna: str,\n",
    "    titulo: str = \"\",\n",
    "    figsize: tuple = (8, 5),\n",
    "    palette: list = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plota um countplot (gráfico de contagem) usando Seaborn.\n",
    "\n",
    "    Args:\n",
    "        dados (pd.DataFrame): DataFrame com os dados.\n",
    "        coluna (str): Nome da coluna categórica a ser plotada.\n",
    "        titulo (str, opcional): Título do gráfico.\n",
    "        figsize (tuple, opcional): Tamanho da figura (largura, altura). Padrão (8,5).\n",
    "        palette (list, opcional): Lista de cores personalizadas\n",
    "\n",
    "    Returns:\n",
    "        Figura com o gráfico.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    ax = sns.countplot(\n",
    "        data=dados,\n",
    "        x=coluna,\n",
    "        palette=palette\n",
    "    )\n",
    "\n",
    "    # Exibir valores acima das barras\n",
    "\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fontsize=12)\n",
    "\n",
    "    # Título e formatação\n",
    "    plt.title(titulo, fontsize=16, fontweight=\"bold\", loc=\"left\")\n",
    "    plt.xlabel(coluna, fontsize=13)\n",
    "    plt.ylabel(\"Contagem\", fontsize=13)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ca624ff-4700-4044-8106-e7b4bb2c2237",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "selecionando as colunas"
    }
   },
   "outputs": [],
   "source": [
    "colunas_selecionadas = ['valor_gasto_apos_visualizar', 'qtd_trascoes_apos_visualizar', 'ticket_medio_apos_visualizar', 'age', 'credit_card_limit', 'discount_value', 'duration', 'min_value', 'tempo_de_registro', 'num_channels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "066d8eb6-cec2-4688-92b7-4d0cfff0f0e9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Gráfico de correlação"
    }
   },
   "outputs": [],
   "source": [
    "heatmap_corr(dados_drop[colunas_selecionadas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bebaa6f4-1a0e-409e-9e0d-f8bf70a93b23",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Detecção de outliers"
    }
   },
   "outputs": [],
   "source": [
    "plotar_outliers(dados_drop[colunas_selecionadas])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a531af1-9f29-4e7d-8468-8f59ddfe3010",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "distribuição da variável alvo"
    }
   },
   "outputs": [],
   "source": [
    "plot_countplot(dados, 'target', 'Distribuição target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76d3bff2-f1b4-46b6-89df-355c57fa40ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Desenvolvimento dos modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2e6fc8a-478a-4241-a8cd-cfdb83726530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Devemos primeiro definir qual métrica vamos maximizar, considerando a necessidade do negócio. Nosso objetivo é desenvolver um modelo que auxilie na decisão de qual oferta enviar para cada cliente. Entre as opções temos:\n",
    "\n",
    "* Acurácia: Mede a proporção de previsões corretas, ou seja, tanto de clientes que aceitariam a oferta quando dos que não aceitariam, em relação ao total de previsões. \n",
    "\n",
    "* Precisão (precision): Mede, de todas as vezes em que o modelo previu que um cliente aceitaria a oferta, quantas vezes de fato ele acertou. Uma alta precisão é importante em casos onde o custo do FALSO POSITIVO  é alto. Para o nosso contexto, um FALSO POSITIVO é um cliente que o modelo que disse aceitaria a oferta, mas na realidade não aceita. O custo real seria enviar uma oferta para um cliente que não vai converter. \n",
    "\n",
    "* Recall (sensibilidade): Mede, de todos os clientes que realmente aceitariam a oferta, quantos o modelo conseguiu identificar corretamente. Um alto recall é importante quando o custo de um FALSO NEGATIVO é alto. Um FALSO NEGATIVO para o nosso contexto seria um cliente que aceitaria a oferta, mas o modelo previu que não, e portanto a oferta não é enviada para ele. O custo seria a perda.\n",
    "\n",
    "* F1-Score: É a média harmônica entre Precisão e Recall. É útil quando é necessário ter um equilíbrio entre as duas. F1-Score somente é alto quando ambas as métricas forem altas também.  \n",
    "\n",
    "* AUC-ROC: A curva ROC mostra a capacidade do modelo de distinguir entre as classes positivas e negativa. A AUC é area sob essa curva que varia entre 0.5 e 1. Avalia o desempenho do modelo em todos os limiares possíveis. \n",
    "\n",
    "Pensando o F1-Score é a métrica que eu escolhi para maximizar que está alinhada com os objetivos do negócio. O F1 vai me dar um ótimo balanço entre não despedicar as ofertas (Precisão) e não perder oportunidades (Recall). Vamos mostrar todas as métricas, mas nosso foco em maximizar vai ser o **F1-SCORE**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5cd7b9f-1d07-444a-85b8-caa9e0f85e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Estrutura do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f991d08b-755e-4094-bb68-e5fcd1a4e297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Registrar o modelo usando MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b4cc9d-3b49-4c91-9509-f8989954d7b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O MLflow tenta simplificar e automatizar essas etapas difíceis, mas necessárias, do ciclo de vida do aprendizado de máquina. MLflow é uma plataforma de código aberto usada para ajudar os usuários a gerenciar o ciclo de vida de ML, fornecendo rastreamento de experimentos, reprodutibilidade, implantação e um registro de modelo centralizado.\n",
    "\n",
    "Quando registramos um modelo no Databricks com a ajuda do MLFlow, artefatos e metadatos importante são capturados. Isso garante que o modelo desenvolvido, não seja apenas capaz de ser reproduzido no ambiente, mas também que esteja completamente pronto para a implantação com as dependências necessárias.\n",
    "\n",
    "![](https://www.databricks.com/wp-content/uploads/2020/04/databricks-adds-access-control-to-mlflow-model-registry_01.jpg)\n",
    "\n",
    "Portando, vamos utilizar o MLFlow para registrar as execuções dos modelos desenvolvidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc07f2b-4b12-4ad6-8fe2-42b99c321b5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Formulação do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8704f125-79c5-41f1-9265-27ed41318d89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "A formulação do projeto que vamos adotar é estimar a probabilidade de conversão para cada cliente por oferta e então escolher a oferta com maior probabilidade. Isso é mais útil que treinar um modelo que vai apenas dizer \"O cliente vai aceitar a oferta\".\n",
    "\n",
    "\n",
    "A minha proposta é aplicar 2 técnicas de modelagem de *machine learning*, sendo elas:\n",
    "\n",
    "* *Bagging*;\n",
    "* *Boosting*.\n",
    "\n",
    "Após a aplicação dessas técnicas, analisaremos qual apresentou o melhor desempenho de acordo com a métrica escolhida. \n",
    "\n",
    "Antes de passarmos para as técnicas, precisamos definir um modelo como *baseline* a ser ultrapassado. Vamos utilizar o `DecisionTreeClassifier` como nosso *baseline*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7658b610-0ff7-4141-8872-8e985a460826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Bagging - RandomForestClassifier\n",
    "\n",
    "Bagging vem de *Bootstrap Aggregating*:\n",
    "\n",
    "* Bootstrap = criar várias amostras diferentes dos dados originais (com reposição).\n",
    "\n",
    "* Aggregating = juntar as previsões de todos os modelos (por média ou votação)\n",
    "\n",
    "\n",
    "**Funcionamento:**\n",
    "\n",
    "1. Temos o conjunto de dados inicial.\n",
    "\n",
    "2. Gera diversas amostras aleatórias com reposição a partir desse conjunto de dados.\n",
    "\n",
    "3. Para cada amostra aleatória gerada, treina um modelo diferente (uma árvore de decisão no nosso caso).\n",
    "\n",
    "4. Ao final, junta os resultados de todos os modelos. Como é uma classificação, o resultado será a votação da maioria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc3189a-80f1-401b-8a7f-08d00685f1e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Boosting - XGBoost\n",
    "\n",
    "Boosting é uma técnica que vai aprendendo com erros dos preditores anteriores, ou seja, modelos simples que são treinados em sequência, onde cada um tenta corrigir os erros dos anteriores. \n",
    "\n",
    "**Funcionamento:**\n",
    "\n",
    "1. Temos a base de dados inicial\n",
    "2. Treinamos o primeiro modelo\n",
    "3. Avaliamos onde ele errou\n",
    "4. Dá mais peso para os exemplos onde ele errou\n",
    "5. Treina o segundo modelo, porém focando em corrigir esses erros\n",
    "6. Repete o processo, até o total de modelos indicados (no nosso caso o número de árvores de decisão)\n",
    "7. Combina todas as previsões (Geralmente usando uma média ponderada ou soma com pesos)\n",
    "\n",
    "Para a nosa implementação usaremos o [XGBoost](https://xgboost.readthedocs.io/en/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "992d77b8-ec7c-4588-a5c8-a7921e1834b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Implementando a estrutura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a00c584-ed62-4232-b72a-f0e45333a2e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = dados.drop(columns=['target'])\n",
    "y = dados['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da2f835c-1071-4464-b0a8-11164af0a0c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_cols = ['age', 'credit_card_limit',\n",
    "        'tempo_de_registro', 'discount_value', 'duration',\n",
    "       'min_value', 'num_channels', 'email',\n",
    "       'mobile', 'social', 'web']\n",
    "\n",
    "cat_cols = ['gender', 'offer_type', 'categoria_duracao']\n",
    "\n",
    "cols_drop = ['account_id', 'offer_id_final', 'offer_received', 'offer_viewed',\n",
    "    'valor_gasto_apos_visualizar', 'qtd_trascoes_apos_visualizar',\n",
    "    'ticket_medio_apos_visualizar', 'registered_on']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be770c5c-690b-4212-a67f-64a74c55cf30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Removemos `account_id` e `offer_id_final` pois são identificadores. `registered_on` é uma data, e já temos o `tempo_de_registro` como uma variável numérica.\n",
    "\n",
    "O motivo de remover `valor_gasto_apos_visualizar`, `qtd_trascoes_apos_visualizar` e `ticket_medio_apos_visualizar` é um pouco mais interessante. Essas variáveis contém informações sobre o resultado que estamos tentando prever, mas que só estariam disponíveis depois do evento acontecer. Nosso objetivo é prever se um cliente vai completar a oferta antes de enviá-la. O valor que o cliente gastou após visualizar a oferta ou mesmo depois de receber poderia dar dicas ao modelo que não queremos. Seria algo como \"Se o clinte gastou muito após visualizar a oferta, prever que ele vai completar\". Mas no momento do envio da oferta não sabemos se ele vai gastar muito ou pouco. \n",
    "\n",
    "`offer_received` e `offer_viewed` são as variáveis da \"história\" do cliente, como mencionado no notebook 1. Indicam os estágios da conversão. `offer_received` sempre vai ser 1 para todas as linhas. Elas também não ajudam na decisão principal. A decisão de \"qual oferta enviar\" acontece antes mesmo de sabermos se o cliente irá sequer visualizá-la. Incluir a coluna `offer_viewed` pode confundir o modelo. Queremos prever o sucesso da oferta do cliente, e as características do cliente e da oferta são as causas que levam a esse sucesso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d253419d-72ec-4dc0-97b6-cf90419fb826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Pipeline de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48e2ef66-be27-4974-b716-5afc1ad50eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O pipeline de ML abaixo está englobando algumas etapas do processo de modelagem, como:\n",
    "\n",
    "* Treinamento do modelo de machine learning. Nesse caso estamos testando 3 modelos. Decision Tree, Random Forest e XGBoost\n",
    "\n",
    "* Otimização dos hiperparâmetros desses modelos para decidir qual técnica/modelo teve melhor desempenho\n",
    "\n",
    "* Registro no MLFlow dos 3 melhores modelos otimizados.\n",
    "\n",
    "* Salvar os 3 melhores modelos no Unity Catalog utilizando o MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0724b6d7-49c9-4df0-985f-52d80e04650c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports adicionais necessários\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def espaco_busca_dt(trial):\n",
    "    return {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        # 'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        # 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        # 'random_state': 42\n",
    "    }\n",
    "\n",
    "def espaco_busca_rf(trial):\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        # 'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "        # 'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 15),\n",
    "        # 'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        # 'random_state': 42\n",
    "    }\n",
    "\n",
    "def espaco_busca_xgb(trial):\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 400, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        # 'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        # 'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        # 'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        # 'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        # 'objective': 'binary:logistic',\n",
    "        # 'eval_metric': 'logloss',\n",
    "        # 'random_state': 42\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99aec300-fdf7-4afc-b298-4715e8840d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial, model_class, espaco_busca, X_train, y_train, X_test, y_test, cat_cols, num_cols):\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        \n",
    "        params = espaco_busca(trial)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        model = model_class(**params)\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', num_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        \n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='f1')\n",
    "\n",
    "        mean_f1 = np.mean(scores)\n",
    "        mlflow.log_metric('mean_cv_f1_score', mean_f1)\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ffee202-611b-4e61-9b94-de16fd1f1894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def otimizar_e_registrar_modelo(\n",
    "    X, y, colunas_para_dropar, cat_cols, num_cols, \n",
    "    model_name, model_class, espaco_busca_modelo, \n",
    "    n_trials=50\n",
    "):\n",
    "\n",
    "    X_model = X.drop(columns=colunas_para_dropar)\n",
    "    X_model[num_cols] = X_model[num_cols].astype(\"float64\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_model, y, random_state=42, stratify=y)\n",
    "    \n",
    "    TZ_MINUS3 = timezone(timedelta(hours=-3))\n",
    "    timestamp = datetime.now(TZ_MINUS3).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    run_name = f\"Otimizacao_{model_name}_{timestamp}\"\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as parent_run:\n",
    "        print(f\"--- Iniciando otimização para o modelo: {model_name} ---\")\n",
    "        mlflow.set_tag(\"model_type\", model_name)\n",
    "\n",
    "        objective_com_dados = partial(\n",
    "            objective,\n",
    "            model_class=model_class,\n",
    "            espaco_busca=espaco_busca_modelo,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test, y_test=y_test,\n",
    "            cat_cols=cat_cols, num_cols=num_cols\n",
    "        )\n",
    "        \n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective_com_dados, n_trials=n_trials)\n",
    "        \n",
    "        mlflow.log_params(study.best_params)\n",
    "\n",
    "        best_model = model_class(**study.best_params)\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', num_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "            ]\n",
    "        )\n",
    "        best_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', best_model)])\n",
    "        best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = best_pipeline.predict(X_test)\n",
    "        y_pred_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "        metrics = {\n",
    "            'Acurácia': accuracy_score(y_test, y_pred),\n",
    "            'Precisão': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred)\n",
    "        }\n",
    "\n",
    "        print(\"Gerando e registrando visualizações...\")\n",
    "        \n",
    "        labels = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "        categories = [\"Não completada\", \"Completada\"]\n",
    "        \n",
    "        fig_cm = plot_matriz_confusao(\n",
    "            y_test, \n",
    "            y_pred, \n",
    "            group_names=labels,\n",
    "            categories=categories,\n",
    "            title=f\"Matriz de Confusão para {best_model.__class__.__name__}\",\n",
    "            figsize=(15, 5)\n",
    "        )\n",
    "        mlflow.log_figure(fig_cm, \"matriz_de_confusao.png\")\n",
    "        plt.close(fig_cm)\n",
    "        \n",
    "        fig_roc = plot_roc_auc(y_test, y_pred_proba)\n",
    "        mlflow.log_figure(fig_roc, \"curva_roc_auc.png\")\n",
    "        plt.close(fig_roc)\n",
    "\n",
    "        print(f\"Registrando o modelo '{model_name}' no MLflow...\")\n",
    "\n",
    "        # Modelo e Avaliação Automática\n",
    "        signature = infer_signature(X_train, y_pred)\n",
    "\n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            sk_model=best_pipeline,\n",
    "            artifact_path=\"modelo\",\n",
    "            signature=signature,\n",
    "            registered_model_name=f\"workspace.modelos_ml.{model_name}\"\n",
    "        )\n",
    "\n",
    "        evaluation_data = X_test.copy()\n",
    "        evaluation_data[\"target\"] = y_test\n",
    "        mlflow.models.evaluate(\n",
    "            model=model_info.model_uri,\n",
    "            data=evaluation_data,\n",
    "            targets=\"target\",\n",
    "            model_type=\"classifier\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Modelo '{model_name}' otimizado e registrado com sucesso!\")\n",
    "        return model_info.model_uri, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aa57bd7-5172-402e-bf33-afd95008f7fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"ArvoreDecisao\": {\n",
    "        \"model_class\": DecisionTreeClassifier,\n",
    "        \"espaco_busca_modelo\": espaco_busca_dt\n",
    "    }\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for model_name, config in MODEL_CONFIG.items():\n",
    "    \n",
    "    # Otimiza o modelo atual\n",
    "    model_uri, info_modelo = otimizar_e_registrar_modelo(\n",
    "        X=X, \n",
    "        y=y,\n",
    "        colunas_para_dropar=cols_drop,\n",
    "        cat_cols=cat_cols,\n",
    "        num_cols=num_cols,\n",
    "        model_name=f\"ModeloOferta_{model_name}\",\n",
    "        model_class=config['model_class'],\n",
    "        espaco_busca_modelo=config['espaco_busca_modelo'],\n",
    "        n_trials=10  # Número de tentativas para cada modelo\n",
    "    )\n",
    "    \n",
    "    info_modelo['Modelo'] = model_name\n",
    "    info_modelo['Modelo_URI'] = model_uri\n",
    "    resultados.append(info_modelo)\n",
    "\n",
    "results_df = pd.DataFrame(resultados).sort_values(by='f1_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a36fe756-f6b0-4af6-8ebd-5c06390cab6a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "final"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"ArvoreDecisao\": {\n",
    "        \"model_class\": DecisionTreeClassifier,\n",
    "        \"espaco_busca_modelo\": espaco_busca_dt\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model_class\": RandomForestClassifier,\n",
    "        \"espaco_busca_modelo\": espaco_busca_rf\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model_class\": XGBClassifier,\n",
    "        \"espaco_busca_modelo\": espaco_busca_xgb\n",
    "    }\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for model_name, config in MODEL_CONFIG.items():\n",
    "    \n",
    "    # Otimiza o modelo atual\n",
    "    model_uri, info_modelo = otimizar_e_registrar_modelo(\n",
    "        X=X, \n",
    "        y=y,\n",
    "        colunas_para_dropar=cols_drop,\n",
    "        cat_cols=cat_cols,\n",
    "        num_cols=num_cols,\n",
    "        model_name=f\"ModeloOferta_{model_name}\",\n",
    "        model_class=config['model_class'],\n",
    "        espaco_busca_modelo=config['espaco_busca_modelo'],\n",
    "        n_trials=10  # Número de tentativas para cada modelo\n",
    "    )\n",
    "    \n",
    "    info_modelo['Modelo'] = model_name\n",
    "    info_modelo['Modelo_URI'] = model_uri\n",
    "    resultados.append(info_modelo)\n",
    "\n",
    "results_df = pd.DataFrame(resultados).sort_values(by='f1_score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb9cceb0-4b8f-4d05-90ff-cfaebe5a3d8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Comparativo Final dos Modelos Otimizados ---\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6197f801-1580-48dd-a27d-75143e7ec2f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec2105c8-4c3d-40bd-b54a-94b2a5e90692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1) Usando a string 'number' (inclui int e float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c03c130-a96f-40ea-9f30-3e756e3456f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "# Set the alias on the desired version. This example uses version 1.\n",
    "client.set_registered_model_alias(\"workspace.modelos_ml.modelooferta_arvoredecisao\", \"best\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4da0e9e-8604-4e62-8a8c-17aba89479fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_uri = \"models:/workspace.modelos_ml.modelooferta_arvoredecisao@best\"\n",
    "\n",
    "print(f\"Carregando modelo: {model_uri}\")\n",
    "load_model = mlflow.sklearn.load_model(model_uri)\n",
    "print(\"Modelo carregado!\")\n",
    "\n",
    "base = X.drop(columns=cols_drop, errors=\"ignore\")\n",
    "df_cliente = (\n",
    "    base.loc[:, ['age', 'credit_card_limit', 'gender', 'tempo_de_registro']]\n",
    "        .sample(1)\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "offer_features = [\n",
    "    'offer_id_final', 'discount_value', 'duration', 'min_value', 'offer_type',\n",
    "    'categoria_duracao', 'num_channels', 'email', 'mobile', 'social', 'web'\n",
    "]\n",
    "offer_features = list(dict.fromkeys(offer_features))  # garante unicidade mantendo ordem\n",
    "dados_ofertas = dados.loc[:, offer_features].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_scoring = df_cliente.merge(dados_ofertas, how='cross')\n",
    "\n",
    "colunas_modelo = base.columns.tolist()\n",
    "df_scoring = df_scoring.reindex(columns=colunas_modelo, fill_value=0)\n",
    "\n",
    "print(\"Dados do cliente: \")\n",
    "display(df_cliente)\n",
    "\n",
    "print(\"Calculando a probabilidade de aceite para cada oferta...\")\n",
    "probabilidade_aceite = load_model.predict_proba(df_scoring)[:, 1] * 100\n",
    "\n",
    "df_proba_sorted = (\n",
    "    dados_ofertas.assign(probabilidade_aceite=probabilidade_aceite.round(2))\n",
    "                 .sort_values('probabilidade_aceite', ascending=False)\n",
    "                 .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(df_proba_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "943b470a-e3dc-47df-80df-f06908840061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Extra (Mostrar servindo o modelo)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_modeling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
